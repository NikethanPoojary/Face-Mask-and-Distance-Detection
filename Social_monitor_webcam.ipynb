{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import face_detection \n",
    "from sklearn.cluster import DBSCAN\n",
    "from keras.models import load_model\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"\"\n",
    "# Path to Input Video File in the BASE_PATH\n",
    "#FILE_PATH = \"test_video.mp4\"\n",
    "\n",
    "FILE_PATH=\"C:\\\\Users\\\\niket\\\\FACE_MASK_DISTANCE\\\\test_vedio\\\\test_demo5.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DSFDDetector', 'RetinaNetResNet50', 'RetinaNetMobileNetV1']\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Face Detector \n",
    "# Confidence Threshold can be Adjusted, Greater values would Detect only Clear Faces\n",
    "\n",
    "print(face_detection.available_detectors)\n",
    "detector = face_detection.build_detector(\"DSFDDetector\", confidence_threshold=.5, nms_iou_threshold=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_classifier = load_model(\"C:\\\\Users\\\\niket\\\\FACE_MASK_DISTANCE\\\\Models\\\\ResNet50_Classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_distance = 80  # Try with different Values before Finalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Frames :\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "# Load YOLOv3\n",
    "net = cv2.dnn.readNet(BASE_PATH+\"Models/\"+\"yolov3.weights\", BASE_PATH+\"Models/\"+\"yolov3.cfg\")\n",
    "\n",
    "# Load COCO Classes\n",
    "classes = []\n",
    "with open(BASE_PATH+\"Models/\"+\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "print(\"Processing Frames :\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while (cap.isOpened()):  \n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    if ret == False:\n",
    "        break\n",
    "    \n",
    "    # Get Frame Dimentions\n",
    "    height, width, channels = img.shape\n",
    "    \n",
    "    # Detect Objects in the Frame with YOLOv3\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    \n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    \n",
    "    # Store Detected Objects with Labels, Bounding_Boxes and their Confidences\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                \n",
    "                # Get Center, Height and Width of the Box\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Topleft Co-ordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "     \n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    \n",
    "    # Initialize empty lists for storing Bounding Boxes of People and their Faces\n",
    "    persons = []\n",
    "    masked_faces = []\n",
    "    unmasked_faces = []\n",
    "    \n",
    "    # Work on Detected Persons in the Frame\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "\n",
    "            box = np.array(boxes[i])\n",
    "            box = np.where(box<0,0,box)\n",
    "            (x, y, w, h) = box\n",
    "\n",
    "            label = str(classes[class_ids[i]])     #DETECTING PERSON BY YOLO V3 \n",
    "            \n",
    "            if label=='person':\n",
    "\n",
    "                persons.append([x,y,w,h])    #SAVING THE PERSONS IMAGE\n",
    "                \n",
    "                person_rgb = img[y:y+h,x:x+w,::-1]   # Crop & BGR to RGB\n",
    "                detections = detector.detect(person_rgb)\n",
    "                \n",
    "                # If a Face is Detected\n",
    "                if detections.shape[0] > 0:\n",
    "\n",
    "                    detection = np.array(detections[0])\n",
    "                    detection = np.where(detection<0,0,detection)\n",
    "\n",
    "                    # Calculating Co-ordinates of the Detected Face\n",
    "                    x1 = x + int(detection[0])\n",
    "                    x2 = x + int(detection[2])\n",
    "                    y1 = y + int(detection[1])\n",
    "                    y2 = y + int(detection[3])\n",
    "                    \n",
    "                    try :\n",
    "\n",
    "                        # Crop & BGR to RGB\n",
    "                        face_rgb = img[y1:y2,x1:x2,::-1]   \n",
    "\n",
    "                        # Preprocess the Image\n",
    "                        face_arr = cv2.resize(face_rgb, (224, 224), interpolation=cv2.INTER_NEAREST)\n",
    "                        face_arr = np.expand_dims(face_arr, axis=0)\n",
    "                        face_arr = preprocess_input(face_arr)\n",
    "\n",
    "                        # Predict if the Face is Masked or Not\n",
    "                        score = mask_classifier.predict(face_arr)\n",
    "\n",
    "                        # Determine and store Results\n",
    "                        if score[0][0]<0.5:\n",
    "                            masked_faces.append([x1,y1,x2,y2])\n",
    "                        else:\n",
    "                            unmasked_faces.append([x1,y1,x2,y2])\n",
    "                            \n",
    "                            \n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "    # Calculate Coordinates of People Detected and find Clusters using DBSCAN\n",
    "    person_coordinates = []\n",
    "    for p in range(len(persons)):\n",
    "        person_coordinates.append((persons[p][0]+int(persons[p][2]/2),persons[p][1]+int(persons[p][3]/2)))\n",
    "\n",
    "    clustering = DBSCAN(eps=threshold_distance,min_samples=2).fit(person_coordinates)\n",
    "    isSafe = clustering.labels_\n",
    "    \n",
    "    # Count \n",
    "    person_count = len(persons)\n",
    "    masked_face_count = len(masked_faces)\n",
    "    unmasked_face_count = len(unmasked_faces)\n",
    "    safe_count = np.sum((isSafe==-1)*1)\n",
    "    unsafe_count = person_count - safe_count\n",
    "\n",
    "    # Show Clusters using Red Lines\n",
    "    arg_sorted = np.argsort(isSafe)\n",
    "    \n",
    "    for i in range(1,person_count):\n",
    "\n",
    "        if isSafe[arg_sorted[i]]!=-1 and isSafe[arg_sorted[i]]==isSafe[arg_sorted[i-1]]:\n",
    "            cv2.line(img,person_coordinates[arg_sorted[i]],person_coordinates[arg_sorted[i-1]],(0,0,255),2)\n",
    "\n",
    "    # Put Bounding Boxes on People in the Frame\n",
    "    for p in range(person_count):\n",
    "\n",
    "        a,b,c,d = persons[p]\n",
    "\n",
    "        # Green if Safe, Red if UnSafe\n",
    "        if isSafe[p]==-1:\n",
    "            cv2.rectangle(img, (a, b), (a + c, b + d), (0,255,0), 2)\n",
    "        else:\n",
    "            cv2.rectangle(img, (a, b), (a + c, b + d), (0,0,255), 2)            \n",
    "    \n",
    "    # Put Bounding Boxes on Faces in the Frame\n",
    "    # Green if Safe, Red if UnSafe\n",
    "    for f in range(masked_face_count):\n",
    "\n",
    "        a,b,c,d = masked_faces[f]\n",
    "        cv2.rectangle(img, (a, b), (c,d), (0,255,0), 2)\n",
    "\n",
    "    for f in range(unmasked_face_count):\n",
    "\n",
    "        a,b,c,d = unmasked_faces[f]\n",
    "        cv2.rectangle(img, (a, b), (c,d), (0,0,255), 2)\n",
    "\n",
    "    # Show Monitoring Status in a Black Box at the Top\n",
    "    cv2.rectangle(img,(0,0),(width,50),(0,0,0),-1)\n",
    "    cv2.rectangle(img,(1,1),(width-1,50),(255,255,255),2)\n",
    "    \n",
    "    xpos = 15\n",
    "    \n",
    "    string = \"( \" +str(masked_face_count)+\" Masked \"+str(unmasked_face_count)+\" Unmasked \"+\\\n",
    "             str(person_count-masked_face_count-unmasked_face_count)+\" Unknown )\"\n",
    "    cv2.putText(img,string,(xpos,35),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,255),2)\n",
    "\n",
    "    # Write Frame to the Output File\n",
    "    #out_stream.write(img)\n",
    "\n",
    "    # Save the Frame in frame_no.png format (If not required, comment the command below)\n",
    "    #cv2.imwrite(BASE_PATH+\"Results/Frames/\"+str(frame)+\".jpg\",img)      # this line is commeneted\n",
    "\n",
    "    # Use if you want to see Results Frame by Frame\n",
    "    \n",
    "    img = cv2.resize(img, (720, 480)) # ADDED TO RESIZE THE OUTPUT WINDOW\n",
    "    cv2.imshow('results',img)      #I REMOVED THIS COMMENT\n",
    "    \n",
    "    # Exit on Pressing Q Key\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release Streams\n",
    "#out_stream.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Good to Go!\n",
    "print(\"Done !\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
